{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "817dc89c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import librosa as libr\n",
    "import librosa.display as disp\n",
    "from IPython.display import Audio\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1cdbb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchaudio\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import SubsetRandomSampler,Subset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1e26a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b719f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_noisy_data_path = \"./../data/28/noisy_trainset_28spk_wav/\"\n",
    "train_noisy_data_path = \"./../data/28/sample/11/\"\n",
    "train_clean_data_path = \"./../data/28/clean_trainset_28spk_wav/\"\n",
    "#test_noisy_data_path = \"./../data/28/noisy_testset_wav/\"\n",
    "test_noisy_data_path = \"./../data/28/sample/21/\"\n",
    "test_clean_data_path = \"./../data/28/clean_testset_wav/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "702a992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'sample_rate':48000,\n",
    "    'max_duration':10,\n",
    "    'n_fft':1024,\n",
    "    'hop_length':512,\n",
    "    'n_mels':64,\n",
    "    'batch_size':128,\n",
    "    'learning_rate':1e-6,\n",
    "    'epochs':10\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f370405b",
   "metadata": {},
   "source": [
    "dev = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "device = torch.device(dev)  \n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebb2a3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"dev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6e3a904",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self,noisy_path,clean_path, transform=None, sample_rate=None,max_duration=None):\n",
    "        \n",
    "        #get file paths\n",
    "        noisy_all_items = os.listdir(noisy_path)\n",
    "        noisy_files = [item for item in noisy_all_items if os.path.isfile(os.path.join(noisy_path, item))]\n",
    "        noisy_file_paths = [os.path.join(noisy_path, file_name) for file_name in noisy_files]\n",
    "        clean_file_paths = [os.path.join(clean_path, file_name) for file_name in noisy_files]\n",
    "\n",
    "        #initialize variables\n",
    "        self.noisy_data = noisy_file_paths\n",
    "        self.clean_data = clean_file_paths\n",
    "        self.transform = transform\n",
    "        self.sample_rate = sample_rate\n",
    "        self.max_duration = max_duration\n",
    "        self.num_samples = sample_rate*max_duration\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.noisy_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        noisy_waveform, sr = torchaudio.load(self.noisy_data[idx])  \n",
    "        noisy_waveform = torch.tensor(noisy_waveform.numpy().reshape(-1))\n",
    "        if noisy_waveform.shape[0] < self.num_samples:\n",
    "            num_missing_samples = self.num_samples - noisy_waveform.shape[0]\n",
    "            noisy_waveform = F.pad(noisy_waveform, (0, num_missing_samples))\n",
    "        noisy_waveform = torch.tensor(noisy_waveform[:self.num_samples])\n",
    "        if self.transform:\n",
    "            noisy_waveform = self.transform(noisy_waveform)\n",
    "        \n",
    "        \n",
    "        clean_waveform, sr = torchaudio.load(self.clean_data[idx])  \n",
    "        clean_waveform = torch.tensor(clean_waveform.numpy().reshape(-1))\n",
    "        if clean_waveform.shape[0] < self.num_samples:\n",
    "            num_missing_samples = self.num_samples - clean_waveform.shape[0]\n",
    "            clean_waveform = F.pad(torch.tensor(clean_waveform), (0, num_missing_samples))\n",
    "        clean_waveform = torch.tensor(clean_waveform[:self.num_samples])\n",
    "        if self.transform:\n",
    "            clean_waveform = self.transform(clean_waveform)\n",
    "        return noisy_waveform, clean_waveform\n",
    "\n",
    "\n",
    "    def plot_waveform(self,noisy_waveform,clean_waveform):\n",
    "        noisy_waveform = noisy_waveform.numpy().reshape(-1)\n",
    "        clean_waveform = clean_waveform.numpy().reshape(-1)\n",
    "        plt.figure(figsize=(8,5))\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Amplitude\")\n",
    "        plt.title(\"Noisy vs Filtered Signal - Time Domain\")\n",
    "        disp.waveshow(noisy_waveform,sr=self.sample_rate,label=\"Noisy\")\n",
    "        disp.waveshow(clean_waveform,sr=self.sample_rate,label=\"Clean\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b16dee76",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_spectrogram = torchaudio.transforms.MelSpectrogram(sample_rate=config['sample_rate'],\n",
    "                                                      n_fft=config['n_fft'], \n",
    "                                                      hop_length=config['hop_length'], \n",
    "                                                      n_mels=config['n_mels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2796352",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AudioDataset(noisy_path=train_noisy_data_path,\n",
    "                       clean_path=train_clean_data_path,\n",
    "                       sample_rate=config['sample_rate'],\n",
    "                       max_duration=config['max_duration'],\n",
    "                       transform=mel_spectrogram)\n",
    "test_dataset = AudioDataset(noisy_path=test_noisy_data_path,\n",
    "                       clean_path=test_clean_data_path,\n",
    "                       sample_rate=config['sample_rate'],\n",
    "                       max_duration=config['max_duration'],\n",
    "                       transform=mel_spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f0e9478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, perc=0.9):\n",
    "    dataset_indices = list(range(len(dataset)))\n",
    "    random.shuffle(dataset_indices)\n",
    "    train_indices = dataset_indices[:int(len(dataset_indices) * perc)]\n",
    "    val_indices = dataset_indices[int(len(dataset_indices) * perc):]\n",
    "    train_dataset = Subset(dataset, train_indices)\n",
    "    val_dataset = Subset(dataset, val_indices)\n",
    "    return train_dataset,val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22a1e66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = split_dataset(train_dataset,0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4890f0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(372, 42, 234)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset),len(val_dataset),len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e6cae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afa7cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebf2b4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 1, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader),len(val_dataloader),len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9197bfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 64, 938])\n",
      "Shape of y: torch.Size([64, 64, 938]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2bb0055",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, signal_shape):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.downsample = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Upsample with Transposed Convolutional Layers\n",
    "        self.upsample = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.downsample(x)\n",
    "        x = self.upsample(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffbb7174",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (upsample): Sequential(\n",
      "    (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): ConvTranspose2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(signal_shape=(64,938))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89407edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9921b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45366fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, epoch, model, loss_fn, optimizer, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    for batch, (X, y) in enumerate(tqdm(dataloader)):\n",
    "        #X = X.to(device)\n",
    "        #y = y.to(device)\n",
    "        X = X.unsqueeze(1)\n",
    "        #Forwardpropagation\n",
    "        pred = model(X).squeeze(1)\n",
    "        loss = loss_fn(pred, y)\n",
    "        #print_all_grad_fns(loss.grad_fn)\n",
    " \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #if batch % 5 == 0:\n",
    "        loss, current = loss.item(), (batch + 1) * len(X)\n",
    "        loss_sum += loss\n",
    "        #print(f\"epoch: {epoch},training loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    return loss_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "910ca9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_loop(dataloader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            #X = X.to(device)\n",
    "            #y = y.to(device)\n",
    "            X = X.unsqueeze(1)\n",
    "            pred = model(X).squeeze(1)\n",
    "            test_loss += loss_fn(pred, y)\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    print(f\"validation Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60339afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████                              | 2/6 [02:39<05:20, 80.10s/it]"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "#model.to(device)\n",
    "train_loss_history,val_loss_history = [],[]\n",
    "for t in range(1,epochs+1):\n",
    "    train_loss = train_loop(train_dataloader,t, model, loss_fn, optimizer,device)\n",
    "    val_loss  = validate_loop(val_dataloader, model, loss_fn,device)\n",
    "    train_loss_history.append(train_loss)\n",
    "    val_loss_history.append(val_loss)\n",
    "    print(f\"epoch: {t},avg epoch train loss: {train_loss:>7f}\")\n",
    "    print(f\"epoch: {t},avg epoch test loss: {val_loss:>7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f950688",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_loss_history,label='train')\n",
    "plt.plot(val_loss_history,label='test')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc9e86ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(162.0415)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_loop(test_dataloader, model, loss_fn,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714121ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa as libr\n",
    "import librosa.display as disp\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d576de",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_audio,test_outputs = next(iter(test_dataloader))\n",
    "outputs = model(samples).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a506f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=fig_size)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.title(\"Signal Waveform - Time Domain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fae482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sample_path = 'test_sample.wav'\n",
    "wavfile.write(filtered_sample_path, sample_rate, filtered_signal)\n",
    "\n",
    "disp.waveshow(signal,sr=sample_rate)\n",
    "Audio(sample_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60ff6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68220ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86383cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be49d44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveUNet(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.downsample = nn.Sequential(\n",
    "            nn.Conv1d(input_shape[0]*input_shape[1], 64, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.downsample(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e6ebd999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WaveUNet(\n",
       "  (downsample): Sequential(\n",
       "    (0): Conv1d(60032, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (64,938)\n",
    "model = WaveUNet(input_shape)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb9accb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1             [-1, 64, 1, 1]      34,578,496\n",
      "================================================================\n",
      "Total params: 34,578,496\n",
      "Trainable params: 34,578,496\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.23\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 131.91\n",
      "Estimated Total Size (MB): 132.14\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model,input_size=(60032,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41cb7729",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseUNetModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseUNetModel,self).__init__()\n",
    "        self.down_conv_layer_1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64 , kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )        \n",
    " \n",
    "        self.down_conv_layer_2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128 , kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.InstanceNorm2d(128)\n",
    "        ) \n",
    "    \n",
    "        self.down_conv_layer_3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256 , kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.InstanceNorm2d(128)\n",
    "        ) \n",
    "        \n",
    "        self.down_conv_layer_4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256 , kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.Dropout(0.5),   \n",
    "        ) \n",
    "        \n",
    "        self.up_conv_layer_1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 256, kernel_size=(4,5), stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(0.5), \n",
    "        )\n",
    "        \n",
    "        self.up_conv_layer_2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(0.5), \n",
    "        )\n",
    "        \n",
    "        self.up_conv_layer_3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 64, kernel_size=(4,5), stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(), \n",
    "        )\n",
    "                \n",
    "        self.upsample_layer = nn.Upsample(scale_factor=2)\n",
    "        self.zero_pad = nn.ZeroPad2d((1, 0, 1, 0))\n",
    "        self.conv_layer_final = nn.Conv2d(128, 1, kernel_size=2,stride=1, padding=0)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        print('x', x.shape)\n",
    "        enc1 = self.down_conv_layer_1(x) # [4, 64, 32, 469]\n",
    "        print('1', enc1.shape)\n",
    "        enc2 = self.down_conv_layer_2(enc1) # [4, 128, 16, 234]\n",
    "        print('2', enc2.shape)\n",
    "        enc3 = self.down_conv_layer_3(enc2) # [4, 256, 8, 117]\n",
    "        print('3', enc3.shape)\n",
    "        enc4 = self.down_conv_layer_4(enc3) # [4, 256, 4, 58]\n",
    "        print('4', enc4.shape)\n",
    "        print(\"only up.....\")\n",
    "        \n",
    "        dec1 = self.up_conv_layer_1(enc4)\n",
    "        print('d1', dec1.shape) # [4, 256, 8, 117]\n",
    "                 \n",
    "        dec13 = torch.cat((dec1, enc3), 1)\n",
    "        print('d13', dec13.shape) #[4, 512, 8, 117]\n",
    "        \n",
    "        dec2 = self.up_conv_layer_2(dec13)\n",
    "        print('d2', dec2.shape) # [4, 128, 16, 234]\n",
    "                 \n",
    "        dec22 = torch.cat((dec2, enc2), 1)\n",
    "        print('d22', dec22.shape) #[4, 256, 16, 234]\n",
    "        \n",
    "        dec3 = self.up_conv_layer_3(dec22)\n",
    "        print('d3', dec3.shape) # [4, 256, 16, 234]\n",
    "                 \n",
    "        dec31 = torch.cat((dec3, enc1), 1)\n",
    "        print('d31', dec31.shape) #[4, 256, 16, 234]\n",
    "        \n",
    "        final = self.upsample_layer(dec31)\n",
    "        final = self.zero_pad(final)\n",
    "        final = self.conv_layer_final(final)\n",
    "\n",
    "        print(final.shape)\n",
    "        return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0add767b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WaveUNet4(\n",
       "  (downsample1): Sequential(\n",
       "    (0): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (downsample2): Sequential(\n",
       "    (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (downsample3): Sequential(\n",
       "    (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (downsample4): Sequential(\n",
       "    (0): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (middle): Sequential(\n",
       "    (0): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (upsample1): Sequential(\n",
       "    (0): ConvTranspose1d(256, 128, kernel_size=(2,), stride=(2,))\n",
       "    (1): ReLU()\n",
       "    (2): Conv1d(384, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (upsample2): Sequential(\n",
       "    (0): ConvTranspose1d(128, 64, kernel_size=(2,), stride=(2,))\n",
       "    (1): ReLU()\n",
       "    (2): Conv1d(192, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (upsample3): Sequential(\n",
       "    (0): ConvTranspose1d(64, 32, kernel_size=(2,), stride=(2,))\n",
       "    (1): ReLU()\n",
       "    (2): Conv1d(96, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (upsample4): Sequential(\n",
       "    (0): ConvTranspose1d(32, 1, kernel_size=(2,), stride=(2,))\n",
       "    (1): ReLU()\n",
       "    (2): Conv1d(64, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WaveUNet4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b5296638",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [128, 384, 3], expected input[2, 128, 7504] to have 384 channels, but got 128 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWaveUNet4\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m60038\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audio_env/lib/python3.9/site-packages/torchsummary/torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(register_hook)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# make a forward pass\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# remove these hooks\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hooks:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audio_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audio_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[44], line 72\u001b[0m, in \u001b[0;36mWaveUNet4.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     68\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample4(x)\n\u001b[1;32m     70\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmiddle(x)\n\u001b[0;32m---> 72\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsample1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsample2(x)\n\u001b[1;32m     74\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsample3(x)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audio_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audio_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audio_env/lib/python3.9/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audio_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audio_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1568\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1565\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1566\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1568\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1570\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1571\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1572\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1573\u001b[0m     ):\n\u001b[1;32m   1574\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audio_env/lib/python3.9/site-packages/torch/nn/modules/conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/audio_env/lib/python3.9/site-packages/torch/nn/modules/conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    304\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    305\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [128, 384, 3], expected input[2, 128, 7504] to have 384 channels, but got 128 channels instead"
     ]
    }
   ],
   "source": [
    "summary(WaveUNet4(),input_size=(1,60038))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff045ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
