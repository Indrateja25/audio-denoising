{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import torch.nn.functional as F\n",
    "import librosa as libr\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import librosa as libr\n",
    "import librosa.display as disp\n",
    "from IPython.display import Audio\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchaudio.transforms import Resample\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import SubsetRandomSampler,Subset,DataLoader\n",
    "from torchmetrics.audio import ScaleInvariantSignalNoiseRatio\n",
    "from torchmetrics.audio import pesq as PESQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'sample_rate':48000,\n",
    "    'max_duration':4,\n",
    "    'batch_size':16,\n",
    "    'learning_rate': 0.0001,\n",
    "    'lr_decay':(0.9, 0.999),\n",
    "    'epochs':200,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_noisy_data_path = \"./noisy_trainset_28spk_wav/\"\n",
    "train_clean_data_path = \"./clean_trainset_28spk_wav/\"\n",
    "test_noisy_data_path = \"./noisy_testset_wav/\"\n",
    "test_clean_data_path = \"./clean_testset_wav/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self,noisy_path,clean_path, transform=None, sample_rate=None,max_duration=None):\n",
    "\n",
    "        #get file paths\n",
    "        noisy_all_items = os.listdir(noisy_path)\n",
    "        noisy_files = [item for item in noisy_all_items if os.path.isfile(os.path.join(noisy_path, item)) and item.lower().endswith('.wav')]\n",
    "        noisy_file_paths = [os.path.join(noisy_path, file_name) for file_name in noisy_files]\n",
    "        clean_file_paths = [os.path.join(clean_path, file_name) for file_name in noisy_files]\n",
    "\n",
    "        #initialize variables\n",
    "        self.noisy_data = noisy_file_paths\n",
    "        self.clean_data = clean_file_paths\n",
    "        self.transform = transform\n",
    "        self.sample_rate = sample_rate\n",
    "        self.max_duration = max_duration\n",
    "        self.num_samples = sample_rate*max_duration\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.noisy_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        noisy_waveform, sr = torchaudio.load(self.noisy_data[idx])\n",
    "        if sr != config['sample_rate']:\n",
    "            resampler = torchaudio.transforms.Resample(sr, config['sample_rate'])\n",
    "            noisy_waveform = resampler(noisy_waveform)\n",
    "        noisy_waveform = torch.tensor(noisy_waveform.numpy().reshape(-1))\n",
    "        if noisy_waveform.shape[0] < self.num_samples:\n",
    "            num_missing_samples = self.num_samples - noisy_waveform.shape[0]\n",
    "            noisy_waveform = F.pad(noisy_waveform, (0, num_missing_samples))\n",
    "        noisy_waveform = torch.tensor(noisy_waveform[:self.num_samples])\n",
    "\n",
    "        clean_waveform, sr = torchaudio.load(self.clean_data[idx])\n",
    "        if sr != config['sample_rate']:\n",
    "            resampler = torchaudio.transforms.Resample(sr, config['sample_rate'])\n",
    "            clean_waveform = resampler(clean_waveform)\n",
    "        clean_waveform = torch.tensor(clean_waveform.numpy().reshape(-1))\n",
    "        if clean_waveform.shape[0] < self.num_samples:\n",
    "            num_missing_samples = self.num_samples - clean_waveform.shape[0]\n",
    "            clean_waveform = F.pad(torch.tensor(clean_waveform), (0, num_missing_samples))\n",
    "        clean_waveform = torch.tensor(clean_waveform[:self.num_samples])  \n",
    "              \n",
    "        return noisy_waveform, clean_waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, num=16):\n",
    "    dataset_indices = list(range(len(dataset)))\n",
    "    random.shuffle(dataset_indices)\n",
    "    train_indices = dataset_indices[num:]\n",
    "    val_indices = dataset_indices[:num]\n",
    "    train_dataset = Subset(dataset, train_indices)\n",
    "    val_dataset = Subset(dataset, val_indices)\n",
    "    return train_dataset,val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x7fb4a7c18310>, <torch.utils.data.dataloader.DataLoader object at 0x7fb4a7ff6fd0>)\n",
      "Length of train dataloader: 723 batches of 16\n",
      "Length of val dataloader: 1 batches of 16\n",
      "Length of test dataloader: 52 batches of 16\n"
     ]
    }
   ],
   "source": [
    "train_dataset = AudioDataset(noisy_path=train_noisy_data_path,\n",
    "                       clean_path=train_clean_data_path,\n",
    "                       sample_rate=config['sample_rate'],\n",
    "                       max_duration=config['max_duration'],\n",
    "                       )\n",
    "test_dataset = AudioDataset(noisy_path=test_noisy_data_path,\n",
    "                       clean_path=test_clean_data_path,\n",
    "                       sample_rate=config['sample_rate'],\n",
    "                       max_duration=config['max_duration'],\n",
    "                       )\n",
    "\n",
    "train_dataset, val_dataset = split_dataset(train_dataset,16)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "\n",
    "print(f\"Dataloaders: {train_dataloader, test_dataloader}\")\n",
    "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {config['batch_size']}\")\n",
    "print(f\"Length of val dataloader: {len(val_dataloader)} batches of {config['batch_size']}\")\n",
    "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {config['batch_size']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper(noise, clean):\n",
    "    print(noise.shape, clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def denoise_audio(signal,clean_signal ,sample_rate=config['sample_rate'] ,t1=0.0,t2=1.0,save=0):\n",
    "    fft = np.fft.fft(signal)\n",
    "    magnitude = np.abs(fft)\n",
    "    frequency =np.linspace(0,sample_rate,len(magnitude))\n",
    "    psd = fft * np.conj(fft) /  len(signal)\n",
    "    \n",
    "    idx = [(psd >= t1) &  (psd <= t2)]\n",
    "    psd_filtered = psd * idx\n",
    "    filtered_fft = idx * fft\n",
    "\n",
    "    filtered_signal = np.real(np.fft.ifft(filtered_fft))\n",
    "    filtered_signal = filtered_signal.squeeze(0).astype(np.float32)\n",
    "    filtered_signal = torch.Tensor(filtered_signal)\n",
    "\n",
    "    filt_magnitude = np.abs(filtered_signal)\n",
    "    filt_frequency =np.linspace(0,sample_rate,len(filt_magnitude))\n",
    "    \n",
    "    if save:\n",
    "        filtered_sample_path = 'denoised.wav'\n",
    "        wavfile.write(filtered_sample_path, sample_rate, filtered_signal)\n",
    "    try:\n",
    "        ssnr = ScaleInvariantSignalNoiseRatio()\n",
    "        snr_clean = ssnr(signal,clean_signal).item() \n",
    "        snr_denoised = ssnr(filtered_signal, signal).item()\n",
    "\n",
    "        #compute_snr(clean_signal,signal)\n",
    "        pesq = PESQ.PerceptualEvaluationSpeechQuality(fs=16000, mode='wb')\n",
    "        if sample_rate != 16000:\n",
    "            resampler = torchaudio.transforms.Resample(16000)\n",
    "            signal = resampler(signal)\n",
    "            clean_signal = resampler(clean_signal)\n",
    "            filtered_signal = resampler(filtered_signal)\n",
    "\n",
    "        pesq_clean = pesq(clean_signal,signal)#compute_snr(clean_signal,filtered_signal)\n",
    "        pesq_denoised = pesq(clean_signal, filtered_signal)\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        clean_loss = criterion(signal.float(),clean_signal .float())\n",
    "        denoise_loss = criterion(filtered_signal.float(),clean_signal .float())\n",
    "        \n",
    "        return (snr_clean,snr_denoised), (pesq_clean,pesq_denoised), (clean_loss,denoise_loss)\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssnr_scores_clean,ssnr_scores_denoise = [],[]\n",
    "pesq_scores_clean, pesq_scores_denoise = [],[]\n",
    "loss_scores_clean, loss_scores_denoise = [],[]\n",
    "for i, data in enumerate(test_dataloader, 0):\n",
    "      # get the inputs; data is a list of [inputs, labels]\n",
    "      X, y = data\n",
    "      try:\n",
    "            ssnr_res, pesq_res, loss_res = denoise_audio(X,y)\n",
    "            ssnr_scores_clean.append(ssnr_res[0])\n",
    "            ssnr_scores_denoise.append(ssnr_res[1])\n",
    "            pesq_scores_clean.append(pesq_res[0])\n",
    "            pesq_scores_denoise.append(pesq_res[1])\n",
    "            loss_scores_clean.append(loss_res[0])\n",
    "            loss_scores_denoise.append(loss_res[1])\n",
    "      except Exception as e:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.610924019533044, -25.502140606150906)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ssnr_scores_clean),np.mean(ssnr_scores_denoise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.832648, 1.0372517)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pesq_scores_clean),np.mean(pesq_scores_denoise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0007543463, 0.002589878)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(loss_scores_clean),np.mean(loss_scores_denoise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseUNetModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseUNetModel,self).__init__()\n",
    "        \n",
    "        self.down_conv_layer_1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64 , kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )        \n",
    " \n",
    "        self.down_conv_layer_2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128 , kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "        ) \n",
    "    \n",
    "        self.down_conv_layer_3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256 , kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "        ) \n",
    "        \n",
    "        self.down_conv_layer_4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256 , kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.5),   \n",
    "        )\n",
    "\n",
    "        self.down_conv_layer_5 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256 , kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.5),   \n",
    "        ) \n",
    "\n",
    "        self.down_conv_layer_6 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256 , kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.5),   \n",
    "        ) \n",
    "        \n",
    "        self.up_conv_layer_1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 256, kernel_size=(2,3), stride=2, padding=0),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(0.5), \n",
    "        )\n",
    "        \n",
    "        self.up_conv_layer_2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=(2,3), stride=2, padding=0),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(0.5), \n",
    "        )\n",
    "        \n",
    "        self.up_conv_layer_3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=(2,3), stride=2, padding=0),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(0.5), \n",
    "        )\n",
    "\n",
    "        self.up_conv_layer_4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 128, kernel_size=(4), stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(0.5), \n",
    "        )\n",
    "\n",
    "        self.up_conv_layer_5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 64, kernel_size=(4), stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(), \n",
    "        )\n",
    "                \n",
    "        self.upsample_layer = nn.Upsample(scale_factor=2)\n",
    "        self.zero_pad = nn.ZeroPad2d((1, 0, 1, 0))\n",
    "        self.conv_layer_final = nn.Conv2d(128, 1, kernel_size=4, padding=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # print(\"x\", x.shape)\n",
    "        enc1 = self.down_conv_layer_1(x)\n",
    "        # print(\"enc1\", enc1.shape)\n",
    "        enc2 = self.down_conv_layer_2(enc1) \n",
    "        # print(\"enc2\", enc2.shape)\n",
    "        enc3 = self.down_conv_layer_3(enc2) \n",
    "        # print(\"enc3\", enc3.shape)\n",
    "        enc4 = self.down_conv_layer_4(enc3)\n",
    "        # print(\"enc4\", enc4.shape)\n",
    "        enc5 = self.down_conv_layer_5(enc4)\n",
    "        # print(\"enc5\", enc5.shape)\n",
    "        enc6 = self.down_conv_layer_6(enc5)\n",
    "        # print(\"enc6\", enc6.shape)\n",
    "\n",
    "        dec1 = self.up_conv_layer_1(enc6)\n",
    "        # print(\"dec1\", dec1.shape)\n",
    "        dec15 = torch.cat((dec1, enc5), 1)\n",
    "        # print(\"dec15\", dec15.shape)\n",
    "\n",
    "        dec2 = self.up_conv_layer_2(dec15)\n",
    "        # print(\"dec2\", dec2.shape)\n",
    "        dec24 = torch.cat((dec2, enc4), 1)\n",
    "        # print(\"dec24\", dec24.shape)\n",
    "\n",
    "        dec3 = self.up_conv_layer_3(dec24)\n",
    "        # print(\"dec3\", dec3.shape)\n",
    "        dec33 = torch.cat((dec3, enc3), 1)\n",
    "        # print(\"dec33\", dec33.shape)\n",
    "\n",
    "        dec4 = self.up_conv_layer_4(dec33)\n",
    "        # print(\"dec4\", dec4.shape)\n",
    "        dec42 = torch.cat((dec4, enc2), 1)\n",
    "        # print(\"dec42\", dec42.shape)\n",
    "\n",
    "        dec5 = self.up_conv_layer_5(dec42)\n",
    "        # print(\"dec5\", dec5.shape)\n",
    "        dec51 = torch.cat((dec5, enc1), 1)\n",
    "        # print(\"dec51\", dec51.shape)\n",
    "\n",
    "        final = self.upsample_layer(dec51)\n",
    "        # print(\"up\", final.shape)\n",
    "        final = self.zero_pad(final)\n",
    "        # print(\"zero\", final.shape)\n",
    "        final = self.conv_layer_final(final)\n",
    "        # print(\"final\", final.shape)\n",
    "        return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'sample_rate':48000,\n",
    "    'max_duration':4,\n",
    "    'n_fft':1024,\n",
    "    'hop_length':512,\n",
    "    'n_mels':64,\n",
    "    'batch_size':128,\n",
    "    'learning_rate': 5e-5,\n",
    "    'epochs':200,\n",
    "    'val_split':0.9,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataset = AudioDataset(noisy_path=test_noisy_data_path,\n",
    "                       clean_path=test_clean_data_path,\n",
    "                       sample_rate=config['sample_rate'],\n",
    "                       max_duration=config['max_duration'],\n",
    "                       )\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = BaseUNetModel()\n",
    "model1.load_state_dict(torch.load('./model'))\n",
    "model1 = model1.cuda()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 192000]) torch.Size([128, 192000])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 1, 4, 4], expected input[1, 128, 1, 192000] to have 1 channels, but got 128 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1528198/2844288586.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1528198/530671279.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;31m# print(\"x\", x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0menc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_conv_layer_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;31m# print(\"enc1\", enc1.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0menc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_conv_layer_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    453\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 454\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 1, 4, 4], expected input[1, 128, 1, 192000] to have 1 channels, but got 128 channels instead"
     ]
    }
   ],
   "source": [
    "model1.eval()\n",
    "criterion = nn.MSELoss()\n",
    "test_loss,test_ssnr,test_pesq = 0.0,0.0,0.0\n",
    "with torch.no_grad():\n",
    "  for i, data in enumerate(test_dataloader, 0):\n",
    "    X, y = data\n",
    "    X = X.unsqueeze(1)\n",
    "    X, y = Variable(X.cuda()), Variable(y.cuda())\n",
    "    preds = model1(X)\n",
    "    preds = preds.squeeze(1).cuda()\n",
    "\n",
    "    loss = criterion(preds.float().squeeze(1), y.float())\n",
    "    # ssnr_score = get_ssnr(preds, clean)\n",
    "    # pesq_score = get_pesq(preds, clean)\n",
    "\n",
    "    test_loss += loss.item()\n",
    "    # test_ssnr += ssnr_score\n",
    "    # test_pesq += pesq_score\n",
    "\n",
    "print(f'Test: Loss: {test_loss:.4f}')#SSNR: {test_ssnr:.4f} PESQ: {test_pesq:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
